{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuJoCMb2uczegKFJWPwMVY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DebugWithNazi/Machine-Learning-Course/blob/main/Machine_Learning_lecture1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning:** (learning from data )\n",
        "\n",
        "There are 4 types of ML:\n",
        "\n",
        "\n",
        "1.   Supervised ( Regression , Classification )\n",
        "2.   Unsupervised ( Clustering, Dimensionality Reduction, Anomoly detection, Association rule learning)\n",
        "3. Semi supervised\n",
        "4. Reinforcement learning\n"
      ],
      "metadata": {
        "id": "dOPxr9uRvqGd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervised Learning:** in which our system learn pattern from data, data consists of input and output. (it will find relationship between input and output)\n",
        "\n",
        "\n",
        "> Output column is basically labelling so in supervised we have labelled data\n",
        "\n"
      ],
      "metadata": {
        "id": "-Msq7UxWweAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> IQ  | Cgpa | placement\n",
        "\n",
        "\n",
        "> 111  | 7.9  | yes\n",
        "\n",
        "\n",
        "\n",
        "> 97  | 8.0  | yes\n",
        "\n",
        "\n",
        "> 60  | 3.4  | No\n",
        "\n",
        "\n",
        "\n",
        "now on the basis of this data if we give cgpa and iq, our system can give result that yes or no"
      ],
      "metadata": {
        "id": "tvaER0opySiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two parts of supervised learning:\n",
        "\n",
        "\n",
        "> regression (if output column is numerical, then its regression)\n",
        "\n",
        "\n",
        "> classification (if output column is categorical, then its classification)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gg5eUSJEz2Jw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two types of data:\n",
        "\n",
        "\n",
        "> 1) Numerical : age, cgpa, iq, weight\n",
        "\n",
        "\n",
        "> 2) Categorical : Gender, nation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N_P6EwVyz-VI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Un-Supervised Learning**\n",
        "in this we have only input\n",
        "\n",
        "\n",
        "\n",
        "> clustering : ( draw inputs on x-axis and y-axis, then on the basis of data, it will detect which student belongs to which group, consider we have two inputs only iq and cgpa, now it will make clusters or groups, it can also divide multiple inputs in n-dimensions and make clusters )\n",
        "\n",
        "\n",
        "> Dimensionality reduction : ( when we have multiple input columns such as 1000 input clumns, then ur model could be slow, so DR remove extra columns, not impriving data but increasing the input columns ) it can combine multiple columns in one column, so in this way it reduce the columns, in this we will work on PDA (model),\n",
        "\n",
        "\n",
        "> Anomoly detection : ( outliers ko detect karna hy, or uny hatana hy )\n",
        "\n",
        "\n",
        "> Association rule learning : ( association between products/inputs etc, in mart vine and diaper have association with eachother according to a case study, so marts put these both things together )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-IGtYoWe05p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Semi-Supervised:** it is partially supervised and un-supervised ( as labelling is expensive, so in this we have minimum label data and more unlabelled data )\n",
        "\n",
        "\n",
        "> Example: google photos me 1 dafa name batao gy person ka, then on each photo it will label with the same name.\n",
        "\n"
      ],
      "metadata": {
        "id": "rYkzKrqc9JW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Re-inforcement:** no data, it learn by himself and improve slowly like humans, example: self driving cars, no data, but ye ahista ahista learn karta hy ,\n",
        "\n",
        "\n",
        "> agent learn from it's environment, agent will observe, and he follow the policy and rule book, it have punishments and rewards\n",
        "\n"
      ],
      "metadata": {
        "id": "iTvTWIwz-TRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batch vs Online:**\n",
        "in case of batch we train entire data on our machine at once, while in online we train in batches and in this case model not only predict but learn too!"
      ],
      "metadata": {
        "id": "SfLKoFW5RcyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instance based learning vs model based learning:** ( jo model ratta lagata hy wo intance based hy, and jo concept smj kar learning karta hy wo model based hy )"
      ],
      "metadata": {
        "id": "gUFADxJKTYLA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instance based:**\n",
        "KNN (K nearest neigbour),rbf, kernals in this no training and learning\n",
        "\n"
      ],
      "metadata": {
        "id": "FdA3S4W33Zer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model based:** model will draw a boundary by learning from data, this boundary is a decision boundary or a function. expl: linear regression, logistic regression, decision trees,"
      ],
      "metadata": {
        "id": "AenuOFb-4PJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   we need to clean data and remove ouliers in both\n",
        "2.   Not train instance based\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R9GRoL8TR6K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenges in Machine Learning:**\n",
        "\n",
        "\n",
        "1.   Data Collection ( by API and web scrapping )\n",
        "2.   Insufficient or labeled data (if more data then even algorithem does not matter) but insuffiecient data is not good + you can get data but labelled data is a challenge\n",
        "\n",
        "\n",
        "3.   Non representative data (if data is not defining complete result), not representing complete data, it will hamper the performance, it will create sample noise / sampling bias.  exp: 100 indians se pocho, 100 pakistani, 100 australian\n",
        "2.   Poor quality data ( you must need to clear data)\n",
        "\n",
        "\n",
        "5.   irrelevant feature/columns (apky analysis me kuch column esy hen jo contribute e nhi kar rahy, agar kharab data hy tu kharab hi output aye gi)\n",
        "2.   overfitting (apne data ko train kia tu apky model ne usy rat lia bht achi tara but concept nhi lia, ab wo new data py predict nhi kary ga, bas old data py acha predict kar sky ga, so har dafa overfitting ho skti hy so u can get that khn py over fitting hona start hogi)\n",
        "\n",
        "\n",
        "7.   Underfitting ( opposite of overfitting ) ye na training data py acha result dega, na hi test data py\n",
        "2.   Software Integration (is a difficult) so make end to end applications , like web based or apps etc\n",
        "\n",
        "\n",
        "9.   Offline learning/deployment ( sara data deploy karny k bad wapis lao sara then update karky deploy karo on server, so this is also challenging, cause online is also tough )\n",
        "2.   Cost Involved ( if model is bit big level, it's very costly )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "miR1hKWmDfzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applications of Machine Learning:**\n",
        "\n",
        "\n",
        "1.    b2c\n",
        "2.    b2b\n",
        "\n"
      ],
      "metadata": {
        "id": "jK1d6qvqSABb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Applications\n",
        "    \n",
        "    -> Retail : Amazon\n",
        "    -> Banking and Finance\n",
        "    -> Transport\n",
        "    -> Manufacturing\n",
        "    -> Consumer Internet\n",
        "\n",
        "2- ML development Lifecycle\n",
        "\n",
        "    -> Frame the problem\n",
        "    -> Gathering data\n",
        "    -> Data Preprocessing\n",
        "    -> Exploratory data analysis\n",
        "    -> Feature Engineering\n",
        "    -> Model training, evaluation, and selection\n",
        "    -> Model deployement\n",
        "    -> Testing\n",
        "    -> Optimize\n",
        "    "
      ],
      "metadata": {
        "id": "b5YVnpG0Ahca"
      }
    }
  ]
}